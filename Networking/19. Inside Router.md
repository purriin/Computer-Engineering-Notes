## 19.1 Switching Fabrics
- Transfer packet from input link to appropriate output link
- **Switching Rate**: Rate at which packets can be transferred from inputs to outputs
	- Often measured as a multiple of input/output line rate
	- N inputs: Switching rate N times line rate desirable
	- Ideally Rate NR
- 3 Major types of switching fabrics:
	1. Memory
	2. Bus
	3. Interconnection Network

**Switching via Memory**
- First generation routers:
	- Traditional computers with switching under direct control of CPU
	- Packet copies to system's memory
	- Speed limited by memory bandwidth (2 bus crossings per datagram)

**Switching via a Bus**
- Datagram from input port memory to output port memory via shared bus
- **Bus Contention**: Switching speed limited by bus bandwidth
- 32 Gbps bus, Cisco 5600: sufficient speed for access routers

**Switching via Interconnection Network**
- Crossbar, Clos networks, other interconnection nets initially developed to connect processors in multiprocessor
- **Multistage Switch**: nxn switch from multiple stages of smaller switches
- **Exploiting Parallelism**:
	- Fragment datagram into fixed length cells on entry
	- Switch cells through the fabric, reassemble datagram at exit
- Scaling, using multiple switching "planes" in parallel:
	- Speedup, scaleup via parallelism
- Cisco CRS router:
	- Basic unit: 8 switching planes
	- Each plane: 3-stage interconnection network
	- Up to 100's Tbps switching capacity

## 19.2 Port Queuing
**Input Port Queuing**
- If switch fabric slower than input ports combined queuing may occur at input queues
	- Queuing delay and loss due to input buffer overflow!

**Head-Of-The-Line (HOL) Blocking**: Queued datagram at front of queue prevents others in queue from moving forward
- Output port contention: Only one red datagram can be transferred. Lower red packet is *blocked*
- One packet time later: Green packet experiences HOL blocking

**Output Port Queuing**
- Buffering required when datagrams arrive from fabric faster than link transmission rate.
- Drop policy: which datagrams to drop is no free buffers?
	- Datagrams can be lost due to congestion, lack of buffers
- Scheduling discipline chooses among queued datagrams for transmission
	- Priority scheduling - who gets best performance
- Buffering when arrival rate via switch exceeds output line speed
- Queuing (delay) and loss due to output port buffer overflow!

**How Much Buffering?**
- RFC 3439 rule of thumb: average buffering equal to “typical” RTT (say 250 msec) times link capacity C
	- e.g., C = 10 Gbps link: 2.5 Gbit buffer
- More recent recommendation: with N flows, buffering equal to  
$$
\frac{RTT*C}{\sqrt{N}}
$$
- But too much buffering can increase delays
	- Long RTTs: poor performance for realtime apps, sluggish TCP response
	- Recall delay-based congestion control: “keep bottleneck link just full enough (busy) but no fuller”

## 19.3 Buffer Management
- **Drop**: Which packet to add, drop when buffers are full
	- **Tail Drop**: Drop arriving packet
	- **Priority**: Drop/remove on priority basis
- **Marking**: Which packets to mark to signal congestion (ECN, RED)

**Packet Scheduling: FCFS**
- **Packet Scheduling**: Deciding which packet to send next on link
	- First come first served
	- Priority
	- Round Robin
	- Weighted fair queuing
- **FCFS**: Packets transmitted in order of arrival to output port
	- Also known as first in first out (FIFO)

**Scheduling Policies: Priority**
- **Priority scheduling**:
	- Arriving traffic classified, queued by class
	- Any header fields can be used for classification
- Send packet from highest priority queue that has buffered packets
	- FCFS within priority class

**Scheduling Policies: Round Robin**
- **Round Robin (RR) Scheduling**:
	- Arriving traffic classified, queued by class
		- Any header fields can be used for classification
- Server cyclically, repeatedly scans class queues, sending one complete packet from each class if available in turn

**Scheduling Policies: Weighted Fair Queuing**
- **Weighted Fair Queuing (WFQ)**:
	- Generalized Round Robin
	- Each class, $i$, has weight, $w_i$ and gets weighted amount of service in each cycle
$$
\frac{W_i}{\sum_jW_j}
$$
- Minimum bandwidth guarantee (per-traffic-class)