Q: What happens if network layer delivers data faster than application layer removes data from socket buffers?

**Flow Control**: Receiver controls sender so sender won't overflow receiver's buffer by transmitting too much, too fast

## 16.1 TCP Flow Control
- TCP receiver "advertises" free buffer space in `rwnd` field in TCP header
	- `RcvBuffer` size set via socket options (typical default is 4096 bytes)
	- Many operating systems auto adjust `RcvBuffer`
- Sender limits amount of unACKed ("in-flight") data to received `rwnd`
- Guarantees receive buffer will not overflow

## 16.2 TCP Connection Management
- Before exchanging data, sender/receiver "handshake":
	- Agree to establish connection (each knowing the other is willing to establish connection)
	- Agree on connection parameters (e.g., starting seq \#s)
## 16.3 Closing a TCP Connection
- Client, server each close their side of connection
	- Send TCP segment with FIN bit = 1
- Respond to received FIN with ACK
	- On receiving FIN, ACK can be combined with own FIN
- Simultaneous FIN exchanges can be handled
## 16.4 Principles of Congestion Control
**Congestion**: Informally, too many sources sending too much data too fast for network to handle
- Manifestations:
	- Long delays (queuing in router buffers)
	- Packet loss (buffer overflow at routers)
- Different from flow control

**Congestion Control**: Too many senders sending too fast

**Flow Control**: One sender too fast for one receiver
## 16.5 Causes/Costs of Congestion

**Scenario 1**:
- Simplest scenario:
	- One router, infinite buffers
	- Input, output link capacity R
	- Two flows
	- No retransmissions needed
**Scenario 2**:
- One router, finite buffers
- Sender retransmits lost, timed-out packet
	- Application-layer input = application-layer output: $\lambda_{in} = \lambda_{out}$
	- Transport layer input includes retransmissions: $\lambda_{in}' \ge \lambda_{in}$
- Idealization: perfect knowledge
	- Sender sends only when buffers available
- Idealization: some perfect knowledge
	- Packets can be lost (dropped at router) due to full buffers
	- Sender know when packet has been dropped: only resends if packet known to be lost
- Realistic Scenario: un-needed duplicates
	- Packets can be lost, dropped at router due to full buffers - requiring retransmissions
	- But sender times can time out prematurely sending 2 copies, both of which are delivered

**Costs of Congestion**:
- More work (retransmission) for given receiver throughput
- Unneeded retransmissions: link carries multiple copies of a packet
	- Decreasing maximum achievable throughput
- When packet dropped any upstream transmission capacity and buffering used for that packet was wasted

Q: what happens as λin and λin’ increase? 
A: as red λin’ increases, all arriving blue pkts at upper queue are dropped, blue throughput g 0

**Insights**:
- Throughput can never exceed capacity
- Delay increases as capacity approaches
- Loss/retransmission decreases effective throughput
- Un-needed duplicates further decreases effective throughput
- Upstream transmission capacity/buffering wasted for packets lost downstream
## 16.6 Approaches Towards Congestion Control
**End-End Congestion Control**:
- No explicit feedback from network
- Congestion inferred from observed loss, delay
- Approach taken by TCP

**Network-Assisted Congestion Control**:
- Routers provide direct feedback to sending/receiving hosts with flows passing through congested router
- May indicate congestion level or explicitly set sending rate
- TCP ECN, ATM, DECbit protocols